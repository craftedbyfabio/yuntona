---
name: "Gandalf (Lakera)"
url: "https://gandalf.lakera.ai/agent-breaker"
category: "AI Red Teaming"
tier: "Plug & Play"
audience: "Red Team"
risk: "Safe"
agentic: false
llm_risks: []
stages: [test]
tags: 
  - Training
  - Game
  - Injection
---

# Gandalf (Lakera)

The world's most popular AI red teaming game. Learn prompt injection by doing it.

## What It Does

An interactive browser game created by Lakera that teaches prompt injection through hands-on challenges. Players attempt to trick an AI guardian into revealing a secret password across increasingly difficult levels, each adding new defensive layers.

## Security Relevance

The best way to understand prompt injection is to practice it. Gandalf builds intuition for how LLMs can be manipulated — knowledge that directly translates to writing better system prompts and understanding guardrail limitations. Recently expanded to include an Agent Breaker mode for testing agentic AI vulnerabilities.

## When to Use It

Use as a training exercise for security teams new to AI threats. Excellent onboarding tool for red teamers transitioning from traditional AppSec to AI security. Zero setup, zero risk — just open the browser.
